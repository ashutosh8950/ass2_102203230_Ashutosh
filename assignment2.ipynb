{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cVmUwYXz8yU",
        "outputId": "a39404cc-1db9-486e-d339-7127abcd9f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance (Accuracy):\n",
            "\n",
            "    Sampling1  Sampling2  Sampling3  Sampling4  Sampling5\n",
            "M1       0.50   1.000000   0.993464   0.993464       0.75\n",
            "M2       0.75   0.931373   0.928105   0.931373       1.00\n",
            "M3       0.00   0.960784   0.967320   0.970588       1.00\n",
            "M4       0.50   0.996732   0.967320   0.983660       0.75\n",
            "M5       0.00   0.964052   0.944444   0.954248       1.00\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
        "\n",
        "# Download dataset from GitHub\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "file_path = \"Creditcard_data.csv\"\n",
        "response = requests.get(url)\n",
        "with open(file_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assuming 'Class' is the target variable\n",
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Sample size detection formula\n",
        "def compute_sample_size(p=0.5, Z=1.96, E=0.05):\n",
        "    return int((Z**2 * p * (1 - p)) / (E**2))\n",
        "\n",
        "sample_size = compute_sample_size()\n",
        "\n",
        "def balance_dataset(X, y, technique):\n",
        "    if technique == \"Sampling1\":\n",
        "        sampler = RandomUnderSampler()\n",
        "    elif technique == \"Sampling2\":\n",
        "        sampler = RandomOverSampler()\n",
        "    elif technique == \"Sampling3\":\n",
        "        sampler = SMOTE()\n",
        "    elif technique == \"Sampling4\":\n",
        "        sampler = SMOTE(k_neighbors=3)\n",
        "    elif technique == \"Sampling5\":\n",
        "        sampler = NearMiss()\n",
        "    else:\n",
        "        return X, y  # No resampling\n",
        "\n",
        "    X_res, y_res = sampler.fit_resample(X, y)\n",
        "    return X_res, y_res\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"M1\": RandomForestClassifier(),\n",
        "    \"M2\": LogisticRegression(max_iter=500, solver='saga'),  # Increased iterations and changed solver\n",
        "    \"M3\": SVC(),\n",
        "    \"M4\": DecisionTreeClassifier(),\n",
        "    \"M5\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Sampling techniques\n",
        "sampling_techniques = [\"Sampling1\", \"Sampling2\", \"Sampling3\", \"Sampling4\", \"Sampling5\"]\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate models\n",
        "for model_name, model in models.items():\n",
        "    results[model_name] = {}\n",
        "    for technique in sampling_techniques:\n",
        "        X_res, y_res = balance_dataset(X, y, technique)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[model_name][technique] = accuracy\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nModel Performance (Accuracy):\\n\")\n",
        "print(results_df.T)\n",
        "\n",
        "# Save results for GitHub submission\n",
        "results_df.to_csv(\"Model_Accuracy_Results.csv\", index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
        "\n",
        "# Download dataset from GitHub\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "file_path = \"Creditcard_data.csv\"\n",
        "response = requests.get(url)\n",
        "with open(file_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assuming 'Class' is the target variable\n",
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Sample size detection formula\n",
        "def compute_sample_size(p=0.5, Z=1.96, E=0.05):\n",
        "    return int((Z**2 * p * (1 - p)) / (E**2))\n",
        "\n",
        "sample_size = compute_sample_size()\n",
        "\n",
        "def balance_dataset(X, y, technique):\n",
        "    if technique == \"Sampling1\":\n",
        "        sampler = RandomUnderSampler()\n",
        "    elif technique == \"Sampling2\":\n",
        "        sampler = RandomOverSampler()\n",
        "    elif technique == \"Sampling3\":\n",
        "        sampler = SMOTE()\n",
        "    elif technique == \"Sampling4\":\n",
        "        sampler = SMOTE(k_neighbors=3)\n",
        "    elif technique == \"Sampling5\":\n",
        "        sampler = NearMiss()\n",
        "    else:\n",
        "        return X, y  # No resampling\n",
        "\n",
        "    X_res, y_res = sampler.fit_resample(X, y)\n",
        "    return X_res, y_res\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"M1\": RandomForestClassifier(),\n",
        "    \"M2\": LogisticRegression(max_iter=500, solver='saga'),  # Increased iterations and changed solver\n",
        "    \"M3\": SVC(),\n",
        "    \"M4\": DecisionTreeClassifier(),\n",
        "    \"M5\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Sampling techniques\n",
        "sampling_techniques = [\"Sampling1\", \"Sampling2\", \"Sampling3\", \"Sampling4\", \"Sampling5\"]\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate models\n",
        "for model_name, model in models.items():\n",
        "    results[model_name] = {}\n",
        "    for technique in sampling_techniques:\n",
        "        X_res, y_res = balance_dataset(X, y, technique)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[model_name][technique] = accuracy\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nModel Performance (Accuracy):\\n\")\n",
        "print(results_df.T)\n",
        "\n",
        "# Determine the best sampling technique for each model\n",
        "best_techniques = results_df.idxmax()\n",
        "print(\"\\nBest Sampling Technique per Model:\\n\")\n",
        "print(best_techniques)\n",
        "\n",
        "# Save results for GitHub submission\n",
        "results_df.to_csv(\"Model_Accuracy_Results.csv\", index=True)\n",
        "best_techniques.to_csv(\"Best_Sampling_Techniques.csv\", index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAh3N-1c1TES",
        "outputId": "bd4d573a-4b5d-409a-977e-17f631d29eee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance (Accuracy):\n",
            "\n",
            "    Sampling1  Sampling2  Sampling3  Sampling4  Sampling5\n",
            "M1       0.25   1.000000   0.990196   0.993464       0.75\n",
            "M2       0.00   0.931373   0.931373   0.928105       1.00\n",
            "M3       0.00   0.960784   0.967320   0.970588       1.00\n",
            "M4       0.00   0.993464   0.980392   0.986928       0.75\n",
            "M5       0.25   0.964052   0.944444   0.954248       1.00\n",
            "\n",
            "Best Sampling Technique per Model:\n",
            "\n",
            "M1    Sampling2\n",
            "M2    Sampling5\n",
            "M3    Sampling5\n",
            "M4    Sampling2\n",
            "M5    Sampling5\n",
            "dtype: object\n"
          ]
        }
      ]
    }
  ]
}